<!DOCTYPE html>

<!--
  portfolYOU Jekyll theme by yousinix
  Free for personal and commercial use under the MIT license
  https://github.com/yousinix/portfolYOU
-->

<html lang="ko" class="h-100">

<head>

  
  
  

  

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:type" content="website">
  <meta property="og:title" content="{&quot;ko&quot;=&gt;&quot;[RL] Actor Critic&quot;, &quot;en&quot;=&gt;&quot;[RL] Actor Critic&quot;}">
  <meta property="og:description" content="Actor Critic ê°œë…, A2C, A3C, ì½”ë“œ êµ¬í˜„">
  <meta property="og:image" content="">

  <title>{&quot;ko&quot;=&gt;&quot;[RL] Actor Critic&quot;, &quot;en&quot;=&gt;&quot;[RL] Actor Critic&quot;}</title>
  <meta name="description" content="Actor Critic ê°œë…, A2C, A3C, ì½”ë“œ êµ¬í˜„">

  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico">

  <!-- Theme style -->
  <script src="/assets/js/theme.js"></script>

  <!-- Font Awesome CDN -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.4/css/all.css">

  <!-- Bootstrap CSS CDN -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css">

  <!-- Animate CSS CDN -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.css">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="/assets/css/style.css">

</head>


<!--  -->

<body class="h-100 d-flex flex-column">

  <main class="flex-shrink-0 container mt-5">
    <nav class="navbar navbar-expand-lg navbar-themed bg-themed navbar--fixed">

  <a class="navbar-brand" href="/"><h5><b>tonnonssi</b></h5></a>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
    <i class="fas fa-1x fa-bars text-themed"></i>
  </button>

  <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
    <div class="navbar-nav ml-auto"><a class="nav-item nav-link " href="/publication">Publication</a>

      <a class="nav-item nav-link " href="/content">Content</a>

      <a class="nav-item nav-link " href="/project/">Project</a>

      <a class="nav-item nav-link " href="/article/">Article</a>

      <a class="nav-item nav-link " href="https://github.com/tonnonssi"><i class="fab fa-1x fa-github"></i></a>

      

      <div class="nav-item language-toggle language-toggle--nav" data-lang-toggle-container="always">
        <button type="button" class="language-toggle__btn" data-lang-switcher>View in English</button>
      </div>

      <span id="theme-toggler" class="nav-item nav-link d-none" aria-hidden="true"></span>
    </div>
  </div>

</nav>

    <div class="col-lg-10 mx-auto mt-5 markdown-body">
  








<div class="title-container">
  <h1>
    <b>
      <span class="lang-content" data-lang="ko" data-lang-group="post-title">[RL] Actor Critic</span>
      <span class="lang-content" data-lang="en" data-lang-group="post-title">[RL] Actor Critic</span>
    </b>
  </h1>
</div>

<div class="post-metadata text-muted">
  <span class="lang-content" data-lang="ko" data-lang-group="post-meta">
    2025ë…„ 05ì›” 06ì¼ Â· <b>ì•½ 12ë¶„ ì†Œìš”</b>
  </span>
  <span class="lang-content" data-lang="en" data-lang-group="post-meta">
    06 May 2025 Â· <b>12 min read</b>
  </span>
</div>


  <div class="post-description">
    
      <div class="lang-content" data-lang="ko" data-lang-group="post-description"><p>Actor Critic ê°œë…, A2C, A3C, ì½”ë“œ êµ¬í˜„</p>
</div>
    
    
      <div class="lang-content" data-lang="en" data-lang-group="post-description"><p>Actor Critic Notion, A2C, A3C, Code</p>
</div>
    
  </div>



  <div class="post-tags">
    <span class="lang-content" data-lang="ko" data-lang-group="post-tags-label">íƒœê·¸:</span>
    <span class="lang-content" data-lang="en" data-lang-group="post-tags-label">Tags:</span>
    
      <a class="text-decoration-none no-underline" href="/blog/tags#rl">
        <span class="tag badge badge-pill text-primary border border-primary">RL</span>
      </a>
    
  </div>


<!-- ë§ˆí¬ë‹¤ìš´ ë‚´ìš© í‘œì‹œ -->
<!-- í•œêµ­ì–´ ì½˜í…ì¸  -->

<!-- ì˜ì–´ ì½˜í…ì¸  -->

<div id="content-ko" class="lang-content" data-lang="ko">
  
<h2 id="bg-ì •ì±…-ì¤‘ì‹¬-rl-ê°€ì¹˜-ì¤‘ì‹¬-rl">[BG] ì •ì±… ì¤‘ì‹¬ RL, ê°€ì¹˜ ì¤‘ì‹¬ RL</h2>
<p>ê°•í™”í•™ìŠµ êµ¬í˜„ì€ í¬ê²Œ <strong>ì •ì±…</strong> ì¤‘ì  ë°©ë²•ë¡ , <strong>ê°€ì¹˜</strong> ì¤‘ì  ë°©ë²•ë¡  ë‘ ê°œë¡œ ë‚˜ë‰œë‹¤.</p>

<h3 id="ì •ì±…-ì¤‘ì‹¬-rl">ì •ì±… ì¤‘ì‹¬ RL</h3>
<p>ë¨¼ì € ì •ì±… ì¤‘ì  ë°©ë²•ë¡ ì€ ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê·¼ì‚¬í•˜ì§€ ì•Šê³ , ìµœì  ì •ì±…ì„ ì§ì ‘ì ìœ¼ë¡œ ê·¼ì‚¬í•œë‹¤. ì •ì±… ì¤‘ì  ë°©ë²•ë¡ ì€  $\theta$ ë¡œ ì¡°ì •ê°€ëŠ¥í•œ ì •ì±… í•¨ìˆ˜ $\pi_\theta(a|s)$ ë¥¼ ì •ì˜í•˜ê³  ê·¸ë˜ë””ì–¸íŠ¸ ì¡°ì •ì„ í†µí•´ ìµœì  ì •ì±… í•¨ìˆ˜ë¥¼ êµ¬í•œë‹¤. ì´ëŠ” ê¸°ëŒ€ ëˆ„ì  ë³´ìƒì„ ê·¹ëŒ€í™”í•˜ëŠ” ê°•í™”í•™ìŠµì˜ í•™ìŠµ ëª©í‘œë¥¼ ì§ì ‘ì ìœ¼ë¡œ ìµœì í™”í•œë‹¤ëŠ” ì ì—ì„œ ì´ë¡ ì ìœ¼ë¡œ ì¼ê´€ì„±ì´ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. í•˜ì§€ë§Œ ê° ìƒíƒœ-í–‰ë™ ìŒì˜ ì •í™•í•œ ê°€ì¹˜ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì§€ ëª»í•˜ê³ , ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ì¶”ì •ì¹˜ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë¶„ì‚°ì´ ì»¤ì§ˆ ìˆ˜ ìˆìœ¼ë©°, í•™ìŠµ ì•ˆì •ì„±ì„ ì €í•´í•  ìˆ˜ ìˆë‹¤.</p>

<h4 id="ì˜ˆì‹œ">ì˜ˆì‹œ</h4>

\[\nabla_\theta J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \nabla_\theta \log \pi_\theta(a|s) \cdot Q_{\pi_\theta}(s, a) \right]\]

<ul>
  <li>í´ë¦¬ì‰¬ ê·¸ë˜ë””ì–¸íŠ¸ì˜ ì •ì±… ì‹ ê²½ë§ ì—…ë°ì´íŠ¸ ì‹</li>
</ul>

<p>ëŒ€í‘œì ì¸ ì •ì±… ê¸°ë°˜ RLì¸ Reinforce ì•Œê³ ë¦¬ì¦˜ì€ ì•Œ ìˆ˜ ì—†ëŠ” $Q(s, a)$ ì„ ë°˜í™˜ê°’ì¸ $G_t$ë¡œ ì¹˜í™˜í•œë‹¤.</p>

<h3 id="ê°€ì¹˜-ì¤‘ì‹¬-rl">ê°€ì¹˜ ì¤‘ì‹¬ RL</h3>
<p>ê°€ì¹˜ ì¤‘ì‹¬ ê°•í™”í•™ìŠµ ë°©ë²•ë¡ ì€ ì •ì±…ì„ ëª…ì‹œì ìœ¼ë¡œ íŒŒë¼ë¯¸í„°í™”í•˜ì§€ ì•Šê³ , ìƒíƒœ-í–‰ë™ ê°€ì¹˜ í•¨ìˆ˜  $Q(s, a)$ ë¥¼ ê·¼ì‚¬í•˜ì—¬ ê°„ì ‘ì ìœ¼ë¡œ ìµœì  ì •ì±…ì„ ìœ ë„í•œë‹¤. ê°€ì¹˜ í•¨ìˆ˜ê°€ ì˜ ê·¼ì‚¬ëœë‹¤ë©´, ì—ì´ì „íŠ¸ëŠ” ê° ìƒíƒœì—ì„œ ê°€ì¥ ë†’ì€ ê°€ì¹˜ë¥¼ ê°–ëŠ” í–‰ë™ì„ ì„ íƒí•˜ëŠ” ì •ì±…  $\pi(s) = \arg\max_a Q(s, a)$ ì„ ë”°ë¦„ìœ¼ë¡œì¨ ìµœì ì˜ í–‰ë™ ì „ëµì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ë°©ë²•ì€ ì¼ë°˜ì ìœ¼ë¡œ Temporal Difference(ì‹œê°„ì°¨) í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ ë²¨ë§Œ ë°©ì •ì‹ì„ ê·¼ì‚¬í•˜ê³ , ë°˜ë³µì ì¸ ì˜ˆì¸¡-ì—…ë°ì´íŠ¸ ê³¼ì •ì„ í†µí•´ ìˆ˜ë ´í•œë‹¤. ê·¸ëŸ¬ë‚˜ ì •ì±…ì„ ì§ì ‘ ìµœì í™”í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— <strong>í™•ë¥ ì  ì •ì±… í‘œí˜„</strong>ì´ ì–´ë µê³ , ì ì ˆí•œ íƒí—˜(exploration)ì´ ì™¸ë¶€ ë©”ì»¤ë‹ˆì¦˜(ì˜ˆ: Îµ-greedy)ì— ì˜í•´ ë³´ì¥ë˜ì–´ì•¼ ì›í™œí•œ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤.</p>

<hr />
<h3 id="-temporal-differenceì‹œê°„ì°¨-í•™ìŠµ">ğŸ’¡ Temporal Difference(ì‹œê°„ì°¨) í•™ìŠµ</h3>

<p><img src="../assets/images/RL/ActorCritic/image1.png" alt="" /></p>

<p>ì‹œê°„ì°¨ í•™ìŠµ(Temporal Difference Learning)ì€ model-free í™˜ê²½ì—ì„œ í‘œë³¸ ê²½ë¡œë¥¼ ì´ìš©í•´ ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ì¶”ì •í•  ìˆ˜ ìˆëŠ” Monte Carlo ë°©ì‹ì˜ ì¥ì ê³¼, ëª¨ë“  ì—í”¼ì†Œë“œê°€ ì¢…ë£Œë˜ì§€ ì•Šì•„ë„ ì‹œê°„ ë‹¨ê³„ë³„ë¡œ ê°’ì„ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆëŠ” Dynamic Programmingì˜ ì¥ì ì„ ê²°í•©í•œ ë°©ë²•ë¡ ì´ë‹¤. ì´ ë°©ë²•ì€ ë²¨ë§Œ ê¸°ëŒ€ ë°©ì •ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°,</p>

\[v_{\pi}(s) = \mathbb{E}_{\pi}[R_{t+1} + \gamma V_{\pi}(S_{t+1}) | S_t = s]\]

<p>ì˜ ìš°ë³€ì— í•´ë‹¹í•˜ëŠ” ê°’  $R_{t+1} + \gamma V_{\pi}(S_{t+1})$ ì„ TD íƒ€ê²Ÿìœ¼ë¡œ ì‚¼ì•„, ì˜ˆì¸¡ê°’ê³¼ì˜ ì˜¤ì°¨ë¥¼ ì¤„ì—¬ê°€ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•œë‹¤.</p>

<p>ì¼ë°˜ì ìœ¼ë¡œ ì‹œê°„ì°¨ í•™ìŠµì—ì„œëŠ” ë‹¤ìŒ ìƒíƒœì—ì„œì˜ ì˜ˆì¸¡ê°’ì„ ì‚¬ìš©í•˜ì—¬ í˜„ì¬ ê°€ì¹˜ ì¶”ì •ì„ ì—…ë°ì´íŠ¸í•˜ëŠ”ë°, ì´ë•Œ 1ìŠ¤í… TD íƒ€ê²Ÿì„ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì„ TD(0) ë¼ê³  í•œë‹¤.
ë°˜ë©´, ë¯¸ë˜  n  ìŠ¤í…ì— ê±¸ì¹œ ì‹¤ì œ ë³´ìƒ ì‹œí€€ìŠ¤ë¥¼ ì´ìš©í•´ ì—…ë°ì´íŠ¸í•˜ëŠ” ë°©ì‹ì„ TD(n) ì´ë¼ê³  í•˜ë©°,
 $n \to \infty$ ì¸ ê²½ìš°ëŠ” ì—í”¼ì†Œë“œ ì „ì²´ë¥¼ í™œìš©í•˜ëŠ” Monte Carlo ë°©ì‹, ì¦‰ TD(1) ì´ ëœë‹¤.</p>

<h3 id="monte-carlo-vs-bootstrap-in-rl">Monte Carlo vs Bootstrap in RL</h3>
<p>ë¶€íŠ¸ìŠ¤íŠ¸ë©ì€ ë‹¤ìŒ ìƒíƒœì˜ ê°€ì¹˜ ì¶”ì •ì¹˜ë¥¼ í™œìš©í•´ í˜„ì¬ì˜ ê°€ì¹˜ë¥¼ ê°±ì‹ í•˜ëŠ” ë°©ì‹ì´ë‹¤. ì´ëŠ” í•™ìŠµ ì†ë„ê°€ ë¹ ë¥´ê³  ë°ì´í„° ìš´ìš© íš¨ìœ¨ì„±ì´ ë†’ì§€ë§Œ, ì¶”ì •ì¹˜ì— ì˜ì¡´í•´ í¸ì°¨ê°€ ì‹¬í•˜ë‹¤. ë°˜ë©´ ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ì‹ì€ ëª¨ë“  ì—í”¼ì†Œë“œê°€ ì¢…ë£Œëœ ì´í›„ ì „ì²´ ë°˜í™˜ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œë‹¤. ì´ ë°©ì‹ì€ í¸ì°¨ëŠ” ì ì§€ë§Œ, ë¶„ì‚°ì´ í¬ë‹¤ëŠ” ë‹¨ì ê³¼ ì—í”¼ì†Œë“œê°€ ì¢…ë£Œëœ ì´í›„ì—ë§Œ ì—…ë°ì´íŠ¸ê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.</p>

<ul>
  <li><strong>ì‹œê°„ì°¨ í•™ìŠµ, ë‹¤ì´ë‚˜ë¯¹ í”„ë¡œê·¸ë˜ë°</strong>ì€ ì „ë¶€ ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°©ë²•ë¡ ì´ë‹¤.</li>
</ul>

<hr />

<h2 id="actor-critic">Actor Critic</h2>
<p>Actor-Critic ì•Œê³ ë¦¬ì¦˜ì€ ì •ì±… ì¤‘ì‹¬ ë°©ë²•ê³¼ ê°€ì¹˜ ì¤‘ì‹¬ ë°©ë²•ì˜ ì¥ì ì„ ê²°í•©í•œ ë°©ë²•ë¡ ìœ¼ëŸ¬, ì§ì ‘ì ì¸ ì •ì±… ìµœì í™”ì˜ íš¨ìœ¨ì„±ê³¼ Temporal Difference ê¸°ë°˜ í•™ìŠµì˜ ì•ˆì •ì„±ì„ ë™ì‹œì— ì¶”êµ¬í•œë‹¤. ì´ êµ¬ì¡°ëŠ” ì •ì±…ì„ ê·¼ì‚¬í•˜ëŠ” Actorì™€, í•´ë‹¹ ì •ì±…ì˜ ì„±ëŠ¥ì„ TD ì˜¤ì°¨ ê¸°ë°˜ìœ¼ë¡œ í‰ê°€í•˜ì—¬ í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” Criticìœ¼ë¡œ êµ¬ì„±ëœë‹¤. ActorëŠ” ì •ì±… íŒŒë¼ë¯¸í„°ë¥¼ ê·¸ë˜ë””ì–¸íŠ¸ ë°©ì‹ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ë©°, Criticì€ TD ì˜¤ì°¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ê°€ì¹˜ í•¨ìˆ˜ë¥¼ í•™ìŠµí•œë‹¤. ë”°ë¼ì„œ Actor-Criticì€ ì •ì±… ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ TD ê¸°ë°˜ìœ¼ë¡œ ê·¼ì‚¬í•œ êµ¬ì¡°ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤.</p>

<p><img src="../assets/images/RL/ActorCritic/image.png" alt="" /></p>

<p>ì •ì±… ê·¸ë˜ë””ì–¸íŠ¸ ê¸°ë°˜ì˜ ì•¡í„° í¬ë¦¬í‹± ì•Œê³ ë¦¬ì¦˜ì€ ì•„ë˜ì™€ ê°™ì´ ì •ì˜ëœë‹¤.</p>

\[\nabla_\theta J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \nabla_\theta \log \pi_\theta(a|s) \cdot Q_{w}(s, a) \right]\]

<ul>
  <li>$\theta$ : ì •ì±… ì‹ ê²½ë§ì˜ íŒŒë¼ë¯¸í„°</li>
  <li>$w$ : ê°€ì¹˜ ê·¼ì‚¬ ì‹ ê²½ë§ì˜ íŒŒë¼ë¯¸í„°</li>
</ul>

<p>ê·¸ëŸ¬ë‚˜ ìœ„ì™€ ê°™ì€ ë°©ì‹ì€ ìƒ˜í”Œë§ ê¸°ë°˜ ì¶”ì •ì—ì„œ ë¶„ì‚°ì´ ì»¤ì ¸ í•™ìŠµì˜ ë¶ˆì•ˆì •ì„±ì„ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ ì™„í™”í•˜ê¸° ìœ„í•´ Actor-Criticì— ì–´ë“œë²¤í‹°ì§€ í•¨ìˆ˜ë¥¼ ë„ì…í•œ ë°©ë²•ë¡ ì´ <strong>A2C : Advantage Actor-Critic</strong>ì´ë‹¤.</p>

<h3 id="a2c--advantage-actor-critic">A2C : Advantage Actor-Critic</h3>

<blockquote>
  <p>Advantage í•¨ìˆ˜</p>
</blockquote>

\[A(s, a) = Q_w(s, a) - V_v(s)\]

<p>ì–´ë“œë²¤í‹°ì§€ í•¨ìˆ˜ëŠ” ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜  $V_v(s)$ ë¥¼ baselineìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ Q-í•¨ìˆ˜ì˜ ë¶„ì‚°ì„ ì¤„ì´ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•œë‹¤. ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ëŠ” ê° í–‰ë™ì´ ì•„ë‹Œ ìƒíƒœ ê³ ìœ ì˜ ê¸°ëŒ€ ê°€ì¹˜ë¥¼ ê·¼ì‚¬í•˜ê¸° ë•Œë¬¸ì— ë¶„ì‚°ì´ ìƒëŒ€ì ìœ¼ë¡œ ì‘ë‹¤. 
ë”°ë¼ì„œ  A(s, a) ëŠ” ìƒíƒœ-í–‰ë™ ê°€ì¹˜ í•¨ìˆ˜ì—ì„œ ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ë¥¼ ì œí•¨ìœ¼ë¡œì¨, ê° í–‰ë™ì´ ìƒíƒœì—ì„œ ê°–ëŠ” <strong>ìƒëŒ€ì  ìš°ìˆ˜ì„±(advantage)</strong>ë§Œì„ ê°•ì¡°í•˜ë©° ì •ì±… ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë¶„ì‚°ì„ íš¨ê³¼ì ìœ¼ë¡œ ê°ì†Œì‹œí‚¨ë‹¤.</p>

<p>Q-í•¨ìˆ˜ì™€ V-í•¨ìˆ˜ë¥¼ ë³„ë„ë¡œ í•™ìŠµí•˜ì§€ ì•Šê³ , TD ì˜¤ì°¨ë¥¼ ì´ìš©í•˜ì—¬ ì–´ë“œë²¤í‹°ì§€ í•¨ìˆ˜ë¥¼ ê·¼ì‚¬í•  ìˆ˜ ìˆë‹¤. TD ì˜¤ì°¨ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤:</p>

\[\delta_v = R_{t+1} + \gamma V_v(S_{t+1}) - V_v(S_t)\]

<p>ì´ ì˜¤ì°¨ëŠ” ì‹¤ì œ ë³´ìƒê³¼ ìƒíƒœ ê°€ì¹˜ í•¨ìˆ˜ì˜ ì˜ˆì¸¡ ê°„ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ë©°,  $A(s_t, a_t) \approx \delta_v$ ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆë‹¤.
ì´ë¥¼ í™œìš©í•œ ì •ì±… ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:</p>

\[\nabla_\theta J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \nabla_\theta \log \pi_\theta(a|s) \cdot \delta_v \right]\]

<p>ê²°ê³¼ì ìœ¼ë¡œ, ì–´ë“œë²¤í‹°ì§€ í•¨ìˆ˜ëŠ” ìƒíƒœì— ëŒ€í•œ baselineì¸  $V(s)$ ë¥¼ í™œìš©í•˜ì—¬ gradientì˜ ê¸°ëŒ€ê°’ì€ ìœ ì§€í•˜ë©´ì„œ ë¶„ì‚°ì„ ì¤„ì´ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤.</p>

<h4 id="ì¥ë‹¨ì ">ì¥ë‹¨ì </h4>
<p>A2CëŠ” ì˜¨í´ë¦¬ì‰¬ ë°©ë²•ë¡ ìœ¼ë¡œ ì‹¤ì‹œê°„ìœ¼ë¡œ í•™ìŠµê°€ëŠ¥í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ, í•™ìŠµì— ì´ìš©ë˜ëŠ” ìƒ˜í”Œì˜ ìƒê´€ë„ê°€ ë†’ë‹¤ëŠ” í•œê³„ê°€ ì¡´ì¬í•œë‹¤.</p>

<h3 id="a3c---asynchronous-advantage-actor-critic">A3C :  Asynchronous Advantage Actor-Critic</h3>
<blockquote>
  <p>ë…¼ë¬¸ ë°”ë¡œê°€ê¸° : <a href="https://arxiv.org/pdf/1602.01783">Asynchronous Methods for Deep Reinforcement Learning (2016)</a></p>
</blockquote>

<p>A3CëŠ” ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ <strong>ë¹„ë™ê¸°</strong>ì ìœ¼ë¡œ ì‘ë™ì‹œì¼œ A2Cì˜ ìƒ˜í”Œ ê°„ì˜ ìƒê´€ë„ ë¬¸ì œë¥¼ í•´ê²°í•œë‹¤.</p>

<p>A3CëŠ” ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë“¤ì´ ë¶„ë¦¬ëœ í™˜ê²½ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµí•˜ë©°, ì—¬ê¸°ì„œ ë°œìƒí•œ ìƒ˜í”Œì„ ëª¨ì•„ í•™ìŠµí•˜ëŠ” ê¸€ë¡œë²Œ ì‹ ê²½ë§ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.</p>

<p><img src="../assets/images/RL/ActorCritic/image2.png" alt="" /></p>

<p>ê¸€ë¡œë²Œ ì‹ ê²½ë§ì€ ì—ì´ì „íŠ¸ë“¤ì´ ë§Œë“¤ì–´ë‚¸ ì—í”¼ì†Œë“œë¥¼ ì¼ì • íƒ€ì„ ìŠ¤í… ë™ì•ˆ ì €ì¥í•˜ê³ , ì €ì¥í•œ ìƒ˜í”Œì„ ì´ìš©í•´ ì—…ë°ì´íŠ¸ë¥¼ ì§„í–‰í•œë‹¤. ê° ì—ì´ì „íŠ¸ì˜ ì‹ ê²½ë§ì€ ì—…ë°ì´íŠ¸ëœ ê¸€ë¡œë²Œ ì‹ ê²½ë§ìœ¼ë¡œ ì—…ë°ì´íŠ¸ëœë‹¤. A3CëŠ” ì´ëŸ¬í•œ ì‚¬ì´í´ì„ ë°˜ë³µí•˜ë©° ì˜¨í´ë¦¬ì‰¬ì˜ ì¥ì ì„ ì‚´ë ¤ë©´ì„œ ìƒ˜í”Œ ê°„ì˜ ìƒê´€ë„ë¥¼ ë‚®ì¶˜ë‹¤.</p>

<h3 id="a2c-êµ¬í˜„">A2C êµ¬í˜„</h3>
<p>ê°„ë‹¨í•œ ì¹´íŠ¸í´ ì˜ˆì œë¥¼ ì‚¬ìš©í–ˆë‹¤.</p>

<h5 id="00-setting">00 setting</h5>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="c1"># AttributeError: module 'numpy' has no attribute 'bool8' ë°©ì§€ 
</span><span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">np</span><span class="p">,</span> <span class="s">'bool8'</span><span class="p">):</span>
    <span class="n">np</span><span class="p">.</span><span class="n">bool8</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">bool_</span>   
</code></pre></div></div>

<h5 id="01-network">01 Network</h5>

<p><img src="../assets/images/RL/ActorCritic/image3.png" alt="" /></p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## ActorCriticNetwork
</span><span class="k">class</span> <span class="nc">ActorCriticNetwork</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="c1"># actor params 
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">actor_fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">actor_fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

        <span class="c1"># critic params 
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">critic_fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">critic_fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">critic_fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">actor_x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">actor_fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">policy</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">actor_fc2</span><span class="p">(</span><span class="n">actor_x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">critic_x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">critic_fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">critic_x</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">critic_fc2</span><span class="p">(</span><span class="n">critic_x</span><span class="p">))</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">critic_fc3</span><span class="p">(</span><span class="n">critic_x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">policy</span><span class="p">,</span> <span class="n">value</span> 
</code></pre></div></div>

<h5 id="02-agent">02 Agent</h5>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Agent
</span><span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">hyper_parameters</span><span class="p">:</span><span class="nb">dict</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">env</span> 
        <span class="bp">self</span><span class="p">.</span><span class="n">action_size</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">action_space</span><span class="p">.</span><span class="n">n</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">state_shape</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">observation_space</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># hyper params 
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">hyper_parameters</span><span class="p">[</span><span class="s">'gamma'</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">hyper_parameters</span><span class="p">[</span><span class="s">'lr'</span><span class="p">]</span>

        <span class="c1"># actor critic network
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">a2c</span> <span class="o">=</span> <span class="n">ActorCriticNetwork</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">state_shape</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">action_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">a2c</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">lr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">policy</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">a2c</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">policy</span> <span class="o">=</span> <span class="n">policy</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">action_size</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">policy</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span> 

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">action</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">reward</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">next_state</span><span class="p">:</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">done</span><span class="p">:</span><span class="nb">bool</span><span class="p">):</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">a2c</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>

        <span class="n">policy</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">a2c</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">next_value</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">a2c</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">done</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">next_value</span>
        <span class="n">advantage</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">value</span> 

        <span class="c1"># actor(policy) nn 
</span>        <span class="n">action_prob</span> <span class="o">=</span> <span class="n">policy</span><span class="p">[</span><span class="n">action</span><span class="p">]</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">action_prob</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
        <span class="n">actor_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">log_prob</span> <span class="o">*</span> <span class="n">advantage</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span> <span class="c1"># policy update ê³¼ì •ì´ë‹ˆ, value ì‹ ê²½ë§ì´ ê°œì…í•˜ë©´ ì•ˆëœë‹¤. 
</span>
        <span class="c1"># critic nn 
</span>        <span class="n">critic_loss</span> <span class="o">=</span> <span class="n">advantage</span><span class="p">.</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># ì œê³±í•´ mse ê¼´ë¡œ ë³€í™˜ 
</span>
        <span class="c1"># total loss
</span>        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">actor_loss</span> <span class="o">+</span> <span class="n">critic_loss</span>

        <span class="c1"># back propagation 
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">total_loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">total_loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>

</code></pre></div></div>

<h5 id="03-main">03 Main</h5>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Hyper Params
</span><span class="n">HYPER_PARAMETERS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'gamma'</span> <span class="p">:</span> <span class="mf">0.99</span><span class="p">,</span> 
    <span class="s">'lr'</span> <span class="p">:</span> <span class="mf">1e-3</span>
<span class="p">}</span>

<span class="n">N_EPISODES</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">MAX_STEPS</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">PRINT_INTERVAL</span> <span class="o">=</span> <span class="mi">20</span>  


<span class="c1">## Env Setting
</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">env_name</span> <span class="o">=</span> <span class="s">"CartPole-v1"</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">)</span>
<span class="n">env</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1">## main 
</span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="p">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">HYPER_PARAMETERS</span><span class="p">)</span>

<span class="n">reward_history</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_EPISODES</span><span class="p">):</span>
    <span class="n">done</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_n_steps</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="n">get_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">agent</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
            <span class="n">loss_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="n">total_n_steps</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">total_n_steps</span> <span class="o">&gt;=</span> <span class="n">MAX_STEPS</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>

    <span class="n">reward_history</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>
    <span class="n">loss_history</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_list</span><span class="p">))</span>

    <span class="c1"># PRINT_INTERVAL ë§ˆë‹¤ í‰ê·  ì¶œë ¥
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">e</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">PRINT_INTERVAL</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">avg_reward</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">reward_history</span><span class="p">[</span><span class="o">-</span><span class="n">PRINT_INTERVAL</span><span class="p">:])</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_history</span><span class="p">[</span><span class="o">-</span><span class="n">PRINT_INTERVAL</span><span class="p">:])</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"[Episode </span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">] Average Reward: </span><span class="si">{</span><span class="n">avg_reward</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">, Average Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="ì¶œì²˜">ì¶œì²˜</h2>
<ol>
  <li>
    <p><a href="https://cumulu-s.tistory.com/7">ê°•í™”í•™ìŠµì—ì„œì˜ bootstrappingì€ ë¬´ì—‡ì¸ê°€? (What is bootstrapping in RL?)</a></p>
  </li>
  <li>
    <p><a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html">A (Long) Peek into Reinforcement Learning</a></p>
  </li>
  <li>
    <p><a href="https://wnthqmffhrm.tistory.com/20">ê°•í™” í•™ìŠµ - A3C(Asynchronous Advantage Actor-Critic)</a></p>
  </li>
  <li>
    <p><a href="https://medium.com/intro-to-artificial-intelligence/the-actor-critic-reinforcement-learning-algorithm-c8095a655c14">The Actor-Critic Reinforcement Learning algorithm</a></p>
  </li>
  <li>
    <p><a href="https://theaisummer.com/Actor_critics/">The idea behind Actor-Critics and how A2C and A3C improve them</a></p>
  </li>
  <li>
    <p><a href="https://www.yes24.com/Product/Goods/101987210">íŒŒì´ì¬ê³¼ ì¼€ë¼ìŠ¤ë¡œ ë°°ìš°ëŠ” ê°•í™”í•™ìŠµ</a></p>
  </li>
</ol>


</div>

<div id="content-en" class="lang-content" data-lang="en" style="display: none;">
  
<p>To be continueâ€¦</p>


</div>


<!-- ì´ì „ ì´í›„ ê¸€ -->
<br>








<div class="post-navigation">
  
    <a class="prev-post" href="/blog/MARL">
      <span class="lang-content" data-lang="ko" data-lang-group="post-nav-prev">â† ì´ì „ ê¸€: [MARL/01] Multi Agent Reinforcement Learning ê¸°ì´ˆ </span>
      <span class="lang-content" data-lang="en" data-lang-group="post-nav-prev">â† Previous: [MARL/01] Multi Agent Reinforcement Learning Basic </span>
    </a>
  
  
  
</div>

<br><br>
<h3>
  <span class="lang-content" data-lang="ko" data-lang-group="post-comments">ëŒ“ê¸€</span>
  <span class="lang-content" data-lang="en" data-lang-group="post-comments">Comments</span>
</h3>
<br>

</div>

<script src="https://utteranc.es/client.js"
        repo="tonnonssi/tonnonssi.github.io"
        issue-term="pathname"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>

  </main>
  <footer class="mt-auto py-3 text-center">

  <small class="text-muted mb-2">
    <i class="fas fa-code"></i> with <i class="fas fa-heart"></i>
    by <strong>Jimin Lee</strong>
  </small>

  <div class="container-fluid justify-content-center"><a class="social mx-1"  href="mailto:tonnonssi@gmail.com"
       style="color: #6c757d"
       onMouseOver="this.style.color='#db4437'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fas fa-envelope fa-1x"></i>
    </a><a class="social mx-1"  href="https://www.github.com/tonnonssi"
       style="color: #6c757d"
       onMouseOver="this.style.color='#333333'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-github fa-1x"></i>
    </a><a class="social mx-1"  href="https://www.instagram.com/jiringsi"
       style="color: #6c757d"
       onMouseOver="this.style.color='#405de6'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-instagram fa-1x"></i>
    </a><a class="social mx-1"  href="https://www.linkedin.com/in/tonnonssi"
       style="color: #6c757d"
       onMouseOver="this.style.color='#007bb5'"
       onMouseOut="this.style.color='#6c757d'">
      <i class="fab fa-linkedin-in fa-1x"></i>
    </a>

</div><small id="attribution">
    theme <a href="https://github.com/yousinix/portfolYOU">portfolYOU</a>
  </small>

</footer>

  
  <!-- GitHub Buttons -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<!-- jQuery CDN -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

<!-- Popper.js CDN -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js"></script>

<!-- Bootstrap JS CDN -->
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

<!-- wow.js CDN & Activation -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/wow/1.1.2/wow.js"></script>
<script> new WOW().init(); </script>

<!-- Initialize all tooltips -->
<script>
$(function () {
    $('[data-toggle="tooltip"]').tooltip()
})
</script>

<!-- Add LaTex function -->
<script type="text/javascript" async
	src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     extensions: ["tex2jax.js"],
     jax: ["input/TeX", "output/HTML-CSS"],
     tex2jax: {
       inlineMath: [ ['$','$'], ["\\(","\\)"] ],
       displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
       processEscapes: true
     },
     "HTML-CSS": { availableFonts: ["TeX"] }
   });
</script>

<script src="/assets/js/lang.js" defer></script>
</body>

</html>
